{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYi04s2_d_10"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = mnist.data,mnist.target\n",
        "import numpy as np\n",
        "\n",
        "X = np.array(mnist.data)\n",
        "y = np.array(mnist.target)\n",
        "y = y.astype(np.uint8)"
      ],
      "metadata": {
        "id": "thWAHuQukqAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "X = normalize(X)"
      ],
      "metadata": {
        "id": "c--uYDTuohcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#splitting the dataset into train and test set'''  '''\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#Creating Validation set from the training data\n",
        "X_train_1 , X_valid , y_train_1 , y_valid = train_test_split(X_train,y_train,test_size=0.2,random_state=42)\n",
        "\n",
        "C_value_max = 0.0\n",
        "accuracy_max = 0.0\n",
        "C_value = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
        "for i in range(len(C_value)):\n",
        "  svm_cls = LinearSVC(C = C_value[i] , multi_class = 'ovr')\n",
        "  # Fit the model to the training data\n",
        "  svm_cls.fit(X_train_1, y_train_1)\n",
        "\n",
        "  y_pred = svm_cls.predict(X_valid)\n",
        "  accuracy = accuracy_score(y_valid, y_pred)\n",
        "\n",
        "  if accuracy > accuracy_max:\n",
        "    accuracy_max = accuracy\n",
        "    C_value_max = C_value[i]\n",
        "    print(f'C value: {C_value_max}')\n",
        "    print(f'OvR SVM Accuracy: {accuracy:.4f}')\n",
        "\n",
        "print(f'Best C value: {C_value_max}')\n",
        "  #print(f'OvR SVM Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7DrEFAVxcp2",
        "outputId": "f4252e38-f5eb-4284-e1b4-a4f8f9122488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C value: 0.1\n",
            "OvR SVM Accuracy: 0.9066\n",
            "C value: 0.2\n",
            "OvR SVM Accuracy: 0.9097\n",
            "C value: 0.3\n",
            "OvR SVM Accuracy: 0.9113\n",
            "C value: 0.4\n",
            "OvR SVM Accuracy: 0.9118\n",
            "C value: 0.5\n",
            "OvR SVM Accuracy: 0.9122\n",
            "C value: 0.6\n",
            "OvR SVM Accuracy: 0.9125\n",
            "C value: 0.7\n",
            "OvR SVM Accuracy: 0.9127\n",
            "C value: 0.8\n",
            "OvR SVM Accuracy: 0.9129\n",
            "C value: 0.9\n",
            "OvR SVM Accuracy: 0.9130\n",
            "C value: 1.0\n",
            "OvR SVM Accuracy: 0.9135\n",
            "Best C value: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction on test data with the best regularization parameter\n",
        "svm_cls = LinearSVC(C = C_value_max, multi_class = 'ovr')\n",
        "\n",
        "# Fit the model to the training data\n",
        "svm_cls.fit(X_train_1, y_train_1)\n",
        "y_pred = svm_cls.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'OvR SVM Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPftjCf1pdAv",
        "outputId": "35d6b293-87ee-495e-9c7a-9647951cb6be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OvR SVM Accuracy: 0.9148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM Classification**\n",
        "\n",
        "In the One-vs-Rest (OvR) setting for SVM classification, the classification problem is broken down into multiple binary classification tasks. Specifically, for a dataset with n classes, the OvR approach constructs n binary classifiers. Each classifier is responsible for distinguishing one class from the rest of the classes combined.\n",
        "\n",
        "In the context of SVM (Support Vector Machines), when using the OvR approach, the algorithm constructs separate decision boundaries for each class. For each binary classifier, the SVM tries to find a hyperplane that maximizes the margin between the target class and the rest of the data points (the \"rest\" refers to all other classes grouped together). During training, the model learns the hyperplane that best separates a particular class from the others.\n",
        "\n",
        "During inference (or prediction), when a new sample needs to be classified, each of the trained binary classifiers calculates a decision score for the sample. This score represents how confidently the model believes the sample belongs to the target class. After calculating these decision scores across all the classifiers, the class with the highest score is assigned to the sample.\n",
        "\n",
        "To summarize the key steps in inference under OvR SVM:\n",
        "\n",
        "Train n binary classifiers for n classes.\n",
        "For a given test sample, pass the sample through all n classifiers.\n",
        "\n",
        "Each classifier produces a score indicating its confidence that the sample belongs to the corresponding class.\n",
        "The class with the highest score is chosen as the predicted class for the sample.\n",
        "\n",
        "In this approach, sklearn's LinearSVC fits a separate linear decision boundary for each class, and the prediction is based on which classifier outputs the highest confidence score for a given test sample.\n",
        "\n",
        "This method is efficient for multi-class classification and works well in practice, particularly for linearly separable data. However, it can struggle with more complex, non-linear decision boundaries, where other strategies like kernel SVMs may be more suitable."
      ],
      "metadata": {
        "id": "Kn5hLYFa6YmP"
      }
    }
  ]
}